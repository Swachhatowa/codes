{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mysql.connector\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from googletrans import Translator\n",
    "from folium import Map,CircleMarker,Marker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "c=pd.read_csv(\"gender_age_train.csv\")\n",
    "d=pd.read_csv(\"phone_brand_device_model.csv\")\n",
    "events_data=pd.read_csv('events_data.csv',dtype={'device_id': 'string'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_data_missing: 0\n",
      "device_data_missing: 0\n",
      "events_data_missing: 453\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3252950"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"user_data_missing:\",c.device_id.isnull().sum())\n",
    "print(\"device_data_missing:\",d.device_id.isnull().sum())\n",
    "print(\"events_data_missing:\",events_data.device_id.isnull().sum())\n",
    "len(events_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DEVICES DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "phn_brnd=pd.DataFrame(d['phone_brand'].drop_duplicates()).reset_index()\n",
    "phn_brnd.drop(['index'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = Translator()\n",
    "l=[]\n",
    "for i  in range(len(phn_brnd)):\n",
    "    translations = translator.translate([phn_brnd['phone_brand'][i]], dest='en')\n",
    "    for translation in translations:\n",
    "        l.append(translation.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0              vivo\n",
       "1            Xiaomi\n",
       "2              OPPO\n",
       "3           Samsung\n",
       "11          Coolpad\n",
       "            ...    \n",
       "64701    Hengyufeng\n",
       "66501          Oaks\n",
       "71650       Siemens\n",
       "79470         Oledi\n",
       "79851          PPTV\n",
       "Name: eng_brand, Length: 116, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phn_brnd['eng_brand']=l\n",
    "mob_devices=pd.merge(d,phn_brnd,how='left',left_on='phone_brand',right_on='phone_brand')\n",
    "mob_devices['eng_brand'].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### some brands looks like are not real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Unnamed: 0            device_id phone_brand device_model     eng_brand\n",
      "123         123  -942277992798295690          优米            3  Quality rice\n",
      "132         132  1251552303715560512          优米           R1  Quality rice \n",
      " 243\n",
      "Empty DataFrame\n",
      "Columns: [Unnamed: 0, device_id, phone_brand, device_model, eng_brand]\n",
      "Index: [] \n",
      " 0\n",
      "      Unnamed: 0            device_id phone_brand device_model   eng_brand\n",
      "2861        2861 -1145583104199299037          黑米           A1  black rice\n",
      "4213        4213 -1576379705054644712          黑米           A1  black rice \n",
      " 47\n",
      "       Unnamed: 0            device_id phone_brand device_model   eng_brand\n",
      "28927       28927 -4478793803614584475          鲜米         s800  Fresh rice\n",
      "77154       77154  1751236410718403505          鲜米         s800  Fresh rice \n",
      " 2\n",
      "Empty DataFrame\n",
      "Columns: [Unnamed: 0, device_id, phone_brand, device_model, eng_brand]\n",
      "Index: [] \n",
      " 0\n",
      "Empty DataFrame\n",
      "Columns: [Unnamed: 0, device_id, phone_brand, device_model, eng_brand]\n",
      "Index: [] \n",
      " 0\n"
     ]
    }
   ],
   "source": [
    "print(mob_devices[mob_devices['eng_brand']=='Quality rice'].head(2),\"\\n\",len(mob_devices[mob_devices['eng_brand']=='Quality rice']))\n",
    "print(mob_devices[mob_devices['eng_brand']=='Big Coke'].head(2),\"\\n\",len(mob_devices[mob_devices['eng_brand']=='Big Coke']))\n",
    "print(mob_devices[mob_devices['eng_brand']=='black rice'].head(2),\"\\n\",len(mob_devices[mob_devices['eng_brand']=='black rice']))\n",
    "print(mob_devices[mob_devices['eng_brand']=='Fresh rice'].head(2),\"\\n\",len(mob_devices[mob_devices['eng_brand']=='Fresh rice']))\n",
    "print(mob_devices[mob_devices['eng_brand']=='Bacardi'].head(2),\"\\n\",len(mob_devices[mob_devices['eng_brand']=='Bacardi']))\n",
    "print(mob_devices[mob_devices['eng_brand']==\"Cube Rubik's Cube\"].head(2),\"\\n\",len(mob_devices[mob_devices['eng_brand']==\"Cube Rubik's Cube\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EVENTS DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "event_id       0\n",
       "device_id    453\n",
       "timestamp      0\n",
       "longitude    423\n",
       "latitude     423\n",
       "city           0\n",
       "state        377\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events_data.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing value treatment\n",
    "- Missing device IDs are filled in with device ids from other same lat-longs available\n",
    "- States are filled in with states from other same cities available.\n",
    "- Missing lat longs are filled in with lat longs from other same deviceIDs available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonunique=pd.DataFrame(events_data.groupby(['longitude','latitude'])['device_id'].nunique().sort_values(ascending=False))\n",
    "nonunique=nonunique[nonunique['device_id']>1].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(nonunique)):\n",
    "    a=\"b\"+str(i)\n",
    "    a=events_data[events_data['device_id'].isnull()& (events_data['longitude'] ==nonunique['longitude'][i]) & (events_data['latitude'] ==nonunique['latitude'][i])][['latitude','longitude']]\n",
    "    print(len(a+i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#events_data['device_id']=events_data['device_id'].map(lambda x: '{:.0f}'.format(x)).astype(str)\n",
    "events1=pd.DataFrame(events_data.groupby(['longitude','latitude'])['device_id'].apply(lambda S: S.mode()[0])).reset_index()\n",
    "events_data_final=pd.merge(events_data,events1,how='left', on=['longitude','latitude'])\n",
    "#events_data_final['device_id_x']=events_data_final['device_id_x'].map(lambda x: '{:.0f}'.format(x)).astype(str)\n",
    "#events_data_final['device_id_y']=events_data_final['device_id_y'].map(lambda x: '{:.0f}'.format(x)).astype(str)\n",
    "l=[]\n",
    "for i in range(len(events_data_final)):\n",
    "    if pd.isnull(events_data_final['device_id_x'][i]):\n",
    "        l.append(events_data_final['device_id_y'][i])\n",
    "    else:\n",
    "        l.append(events_data_final['device_id_x'][i])\n",
    "\n",
    "events_data_final['device_id']=l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_state=pd.DataFrame(events_data_final.groupby(['device_id'])['state'].apply(lambda S: S.mode()[0])).reset_index()\n",
    "events_s2=pd.merge(events_data_final,events_state,how='left',left_on=['device_id'],right_on=['device_id'])\n",
    "\n",
    "l=[]\n",
    "for i in range(len(events_s2)):\n",
    "    if pd.isnull(events_s2['state_x'][i]):\n",
    "        l.append(events_s2['state_y'][i])\n",
    "    else:\n",
    "        l.append(events_s2['state_x'][i])\n",
    "        \n",
    "events_s2['state']=l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_latlong=pd.DataFrame(events_s2.groupby(['device_id'])['longitude'].apply(lambda S: S.mode()[0])).reset_index()\n",
    "events_s2=pd.merge(events_s2,events_latlong,how='left',left_on=['device_id'],right_on=['device_id'])\n",
    "\n",
    "l=[]\n",
    "for i in range(len(events_s2)):\n",
    "    if pd.isnull(events_s2['longitude_x'][i]):\n",
    "        l.append(events_s2['longitude_y'][i])\n",
    "    else:\n",
    "        l.append(events_s2['longitude_x'][i])\n",
    "        \n",
    "events_s2['longitude']=l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_latlong1=pd.DataFrame(events_s2.groupby(['device_id'])['latitude'].apply(lambda S: S.mode()[0])).reset_index()\n",
    "events_s2=pd.merge(events_s2,events_latlong1,how='left',left_on=['device_id'],right_on=['device_id'])\n",
    "l=[]\n",
    "for i in range(len(events_s2)):\n",
    "    if pd.isnull(events_s2['latitude_x'][i]):\n",
    "        l.append(events_s2['latitude_y'][i])\n",
    "    else:\n",
    "        l.append(events_s2['latitude_x'][i])\n",
    "        \n",
    "events_s2['latitude']=l\n",
    "data1=events_s2[['latitude','longitude']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "#data1['latitude'].plot()\n",
    "data1['longitude'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "data1['latitude'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2=data1[(data1['longitude']< 69.3) | (data1['latitude']> 35.0)][['latitude','longitude']].drop_duplicates().reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## events_s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import reverse_geocoder as rg\n",
    "results=[]\n",
    "m=[]\n",
    "for i in range(len(data2)):\n",
    "    results.append(rg.search((data2['latitude'][i],data2['longitude'][i])))\n",
    "    m.append(results[i][0]['admin1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2['state_latlong']=m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_latlong=pd.merge(events_s2,data2, how=\"left\",on=[\"latitude\",\"longitude\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_latlong.drop(['device_id_x','longitude_x', 'latitude_x','state_x', 'device_id_y','state_y','longitude_y','latitude_y',\n",
    "                   'index'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data=pd.DataFrame(wrong_latlong.groupby(['state'])['latitude'].apply(lambda S: S.mode()[0])).reset_index()\n",
    "final_data=pd.merge(wrong_latlong,final_data,how='left',left_on=['state'],right_on=['state'])\n",
    "l=[]\n",
    "#m=[]\n",
    "for i in range(len(final_data)):\n",
    "    if pd.isnull(final_data['state_latlong'][i]):\n",
    "        l.append(final_data['latitude_x'][i])\n",
    "        #m.append(final_data['longitude_x'][i])\n",
    "    else:\n",
    "        l.append(final_data['latitude_y'][i])\n",
    "        #m.append(final_data['longitude_y'][i])\n",
    "        \n",
    "final_data['latitude']=l\n",
    "#final_data['longitude']=m\n",
    "#data1=events_s2[['latitude','longitude']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data1=pd.DataFrame(final_data.groupby(['state'])['longitude'].apply(lambda S: S.mode()[0])).reset_index()\n",
    "final_data=pd.merge(final_data,final_data1,how='left',left_on=['state'],right_on=['state'])\n",
    "l=[]\n",
    "#m=[]\n",
    "for i in range(len(final_data)):\n",
    "    if pd.isnull(final_data['state_latlong'][i]):\n",
    "        l.append(final_data['longitude_x'][i])\n",
    "        #m.append(final_data['longitude_x'][i])\n",
    "    else:\n",
    "        l.append(final_data['longitude_y'][i])\n",
    "        #m.append(final_data['longitude_y'][i])\n",
    "        \n",
    "final_data['longitude']=l\n",
    "#final_data['longitude']=m\n",
    "#data1=events_s2[['latitude','longitude']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## events_s2[events_s2['state_latlong']!=events_s2['state']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Merged all the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#events_s2['device_id']=events_s2['device_id'].map(lambda x: '{:.0f}'.format(x)).astype(str)\n",
    "mob_devices['device_id']=mob_devices['device_id'].astype('str')\n",
    "c['device_id']=c['device_id'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merg1=pd.merge(final_data,mob_devices,how='left',on='device_id')\n",
    "tot_data=pd.merge(merg1,c, how='left',on='device_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_data.drop(['longitude_x','latitude_x','longitude_y','latitude_y','state_latlong'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_data=tot_data[tot_data['state'].isin(['MadhyaPradesh','Chhattisgarh','Uttaranchal','JammuandKashmir','Goa','Nagaland'])].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_data['state'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Analysis after merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"    Missing per field \\n\", tot_data.isnull().sum())\n",
    "print(\"----------------------------------------------\")\n",
    "print(\"Number of Device IDs with no info from user and device tables -\",tot_data[tot_data['phone_brand'].isnull()]['device_id'].nunique())\n",
    "print(\"----------------------------------------------\")\n",
    "print(\"Number of Device IDs with info from user and device tables -\",tot_data[tot_data['phone_brand'].notnull()]['device_id'].nunique())\n",
    "print(\"----------------------------------------------\")\n",
    "notmissing_device=tot_data[tot_data['phone_brand'].notnull()]['device_id']\n",
    "missing_device=tot_data[tot_data['phone_brand'].isnull()]['device_id']\n",
    "a=set(notmissing_device)\n",
    "b=set(missing_device)\n",
    "print(\"DeviceIds missing if is present in not missing Device IDs- \",len(a.intersection(b)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Distribution of Users(device_id) across States."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=tot_data[['device_id','state']].drop_duplicates()\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "\n",
    "sns.countplot(x='state',data=data,palette='muted').set_title('Distribution of Users across States')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Distribution of Users across Phone Brands(Consider only 10 Most used Phone Brands).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows',10000)\n",
    "data1=pd.DataFrame(tot_data.groupby(['eng_brand'])['device_id'].nunique()).sort_values('device_id',ascending=False)[:10].reset_index()\n",
    "data1['perc_dist']=(data1['device_id']/sum(data1['device_id'])*100)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2=data1\n",
    "plt.figure(figsize=(12,8))\n",
    "ax=sns.barplot(x='eng_brand',y='perc_dist',data=data2,palette='muted').set_title('Distribution of Users across Phone Brands')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Distribution of Users across Gender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Distribution of Users across Age Segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#notnull_data=tot_data[tot_data['phone_brand'].notnull()].reset_index()\n",
    "l=[]\n",
    "for i in range(len(tot_data)):\n",
    "    if tot_data['age'][i]<= 22:\n",
    "        l.append('<22')\n",
    "    elif 22 < tot_data['age'][i]<= 26:\n",
    "        l.append('23-26')\n",
    "    elif 26 < tot_data['age'][i]<=28:\n",
    "        l.append('27-28')\n",
    "    elif 28 < tot_data['age'][i]<=31:\n",
    "        l.append('29-31')\n",
    "    elif 31 < tot_data['age'][i]<=38:\n",
    "        l.append('31-38')\n",
    "    else:\n",
    "        l.append('39+')\n",
    "\n",
    "tot_data['age_grp']=l\n",
    "\n",
    "data2=tot_data[['gender','device_id']].drop_duplicates()\n",
    "\n",
    "data3=tot_data[['age_grp','device_id']].drop_duplicates()\n",
    "\n",
    "\n",
    "fig,ax=plt.subplots(1,2,figsize=(12,8))\n",
    "\n",
    "sns.countplot(x='gender',data=data2,palette='muted',ax=ax[0]).set_title('Distribution of Users across Gender.')\n",
    "#sns.countplot(x='age',data=user_Data,palette='ch:.25',ax=ax[1]).set_title('Age distribution')\n",
    "#sns.countplot(x='group',order=['M22-','M23-26','M27-28','M29-31','M32-38','M39+','F23-','F24-26','F27-28','F29-32','F33-42','F43+'],data=user_Data,palette='copper',ax=ax[1]).set_title('Group Distribution')\n",
    "sns.countplot(x='age_grp',data=data3,palette='Set1',ax=ax[1]).set_title('Distribution of Users across Age Segments.')\n",
    "\n",
    "\n",
    "\n",
    "total=[len(data2),len(data3)]\n",
    "for i in range(2):\n",
    "    ax[i].legend(loc='upper right', frameon=False)\n",
    "    for tick in ax[i].get_xticklabels():\n",
    "        tick.set_rotation(45)\n",
    "    for p in ax[i].patches:\n",
    "        height = p.get_height()\n",
    "        ax[i].text(p.get_x()+p.get_width()/2.,\n",
    "                height + 3,\n",
    "                '{:1.2f}'.format(height/total[i]*100),\n",
    "                ha=\"center\") \n",
    "\n",
    "        \n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_brands=pd.DataFrame(tot_data.groupby(['eng_brand'])['device_id'].nunique()).sort_values('device_id',ascending=False)[:10].reset_index()['eng_brand']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_top10brand=tot_data[tot_data['eng_brand'].isin(top_brands)]\n",
    "data4=data_top10brand[['device_id','age_grp','state','gender','eng_brand']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. Distribution of Phone Brands(Consider only 10 Most used Phone Brands) for each Age Segment, State, Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data5=pd.DataFrame(data_top10brand.groupby(['age_grp','state','gender','eng_brand'])['device_id'].nunique()).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.treemap(data5, path=['age_grp','state','gender','eng_brand'],values='device_id',width=1000, height=600)\n",
    "fig.data[0].textinfo = 'label+text+value'\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6. Distribution of Gender for each State, Age Segment and Phone Brand(Consider only 10 Most used Phone Brands).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data6=pd.DataFrame(data_top10brand.groupby(['state','age_grp','eng_brand','gender'])['device_id'].nunique()).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = px.treemap(data6, path=['state','age_grp','eng_brand','gender'],values='device_id',width=1000, height=600)\n",
    "fig.data[0].textinfo = 'label+text+value'\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7. Distribution of Age Segments for each State, Gender and Phone Brand(Consider only 10 Most used Phone Brands)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data7=pd.DataFrame(data_top10brand.groupby(['state','gender','eng_brand','age_grp'])['device_id'].nunique()).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.treemap(data7, path=['state','gender','eng_brand','age_grp'],values='device_id',width=1000, height=600)\n",
    "fig.data[0].textinfo = 'label+text+value'\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 8. Hourly distribution of Phone Calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_data.timestamp=pd.to_datetime(tot_data.timestamp)\n",
    "date_data=tot_data[['event_id','timestamp']].set_index('timestamp')\n",
    "date_data_hourly=date_data.resample('H').count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "ax = sns.lineplot(x=\"timestamp\", y=\"event_id\", data=date_data_hourly).set_title('Hourly distribution of Phone Calls')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_data_split=date_data_hourly\n",
    "date_data_split['timestamp']=date_data_split['timestamp'].astype(str)\n",
    "date_data_split['date']=date_data_split['timestamp'].apply(lambda x:x.split(' ')[0])\n",
    "date_data_split['time']=date_data_split['timestamp'].apply(lambda x:x.split(' ')[1])\n",
    "date_data_split.drop(['timestamp'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_data_split['time']=date_data_split['time'].apply(lambda x:x.rsplit(':',1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_data_split=date_data_split.sort_values([\"time\"])\n",
    "plt.figure(figsize=(20,6))\n",
    "ax = sns.lineplot(x=\"time\", y=\"event_id\",hue=\"date\",sort= True,data=date_data_split).set_title('Hourly distribution of Phone Calls')\n",
    "\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 9. Plot the Users on the Map using any suitable package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1=tot_data[['latitude','longitude']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from folium import FeatureGroup, LayerControl, Map, Marker\n",
    "from folium.plugins import HeatMap\n",
    "\n",
    "map_osm = Map(location=[28.730140, 77.225676], zoom_start=6)\n",
    "\n",
    "\n",
    "#data1.apply(lambda row:Marker(location=[row[\"latitude\"], row[\"longitude\"]], \n",
    "                                             # radius=1)\n",
    "                                             #.add_to(map_osm), axis=1)\n",
    "\n",
    "hm_wide = HeatMap( list(zip(data1.latitude.values, data1.longitude.values)),\n",
    "                     min_opacity=0.2,\n",
    "                     radius=17, blur=15,\n",
    "                     max_zoom=6\n",
    "                 )\n",
    "map_osm.add_child(hm_wide)\n",
    "\n",
    "map_osm.save('heatmap_loc.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "map_osm = Map(location=[28.730140, 77.225676], zoom_start=6)\n",
    "\n",
    "\n",
    "data1.apply(lambda row:Marker(location=[row[\"latitude\"], row[\"longitude\"]], \n",
    "                                             radius=1)\n",
    "                                             .add_to(map_osm), axis=1)\n",
    "\n",
    "\n",
    "map_osm.save('locationmap.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import folium\n",
    "from folium.plugins import FastMarkerCluster\n",
    "\n",
    "map_points = Map(location=[28.730140, 77.225676], zoom_start=4)\n",
    "# These two lines should create FastMarkerClusters\n",
    "FastMarkerCluster(data=list(zip(data1.latitude.values, data1.longitude.values))).add_to(map_points )\n",
    "folium.LayerControl().add_to(map_points )\n",
    "\n",
    "for index, row in data1.iterrows():\n",
    "\n",
    "    # generate the popup message that is shown on click.\n",
    "    popup_text = \"{}<br> latitude: {:,}<br> longitude: {:,}\"\n",
    "    popup_text = popup_text.format(\n",
    "                      index,\n",
    "                      row[\"latitude\"],\n",
    "                      row[\"longitude\"]\n",
    "                      )\n",
    "\n",
    "    folium.CircleMarker(location=(row[\"latitude\"],\n",
    "                                  row[\"longitude\"]),\n",
    "                        radius= 4,\n",
    "                        color=\"#007849\",\n",
    "                        popup=popup_text,\n",
    "                        fill=False).add_to(map_points)\n",
    "map_points.save('latlong_count.html')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
